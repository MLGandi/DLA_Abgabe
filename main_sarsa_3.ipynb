{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports ###\n",
    "import gym\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, Flatten, Input, Dense, AveragePooling2D\n",
    "from keras.callbacks import Callback\n",
    "from rl.agents import SARSAAgent\n",
    "from rl.policy import EpsGreedyQPolicy, LinearAnnealedPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions ###\n",
    "class CustomModelCheckpoint(Callback):\n",
    "\n",
    "    def __init__(self, model, path, interval):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.path = path\n",
    "        self.interval = interval\n",
    "\n",
    "    def on_episode_end(self, episode, logs={}):\n",
    "        if episode % self.interval == 0:\n",
    "            self.model.save_weights(self.path.format(episode), overwrite=True)\n",
    "\n",
    "\n",
    "def plot_history(data, title: str, smoothing: bool = False, smoothing_window: int = 100):\n",
    "\n",
    "    if smoothing:\n",
    "        data = np.convolve(data, np.ones((smoothing_window,)\n",
    "                                         )/smoothing_window, mode='valid')\n",
    "        title = title + \" (Smoothed)\"\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(data)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(title)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def rgb_to_gray(rgb):\n",
    "\n",
    "    return tf.tensordot(rgb[..., :3], [0.2989, 0.5870, 0.1140], axes=1)\n",
    "\n",
    "\n",
    "def build_model_cnn(states, actions):\n",
    "\n",
    "    inputs = Input(shape=states)\n",
    "    x = Conv2D(64, (3, 3), activation='leaky_relu')(inputs)\n",
    "    x = tf.squeeze(x, axis=1)\n",
    "    x = AveragePooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='leaky_relu')(x)\n",
    "    x = AveragePooling2D((2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1500, activation='leaky_relu')(x)\n",
    "    x = Dense(500, activation='leaky_relu')(x)\n",
    "    x = Dense(64, activation='leaky_relu')(x)\n",
    "    x = Dense(actions, activation='linear')(x)\n",
    "    outputs = x\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "# def build_model(states, actions):\n",
    "#     inputs = Input(shape=(1,) + states)\n",
    "#     x = Lambda(rgb_to_gray)(inputs)  # Apply rgb_to_gray function to input\n",
    "#     #x = Flatten()(inputs)\n",
    "#     x = Flatten()(x)\n",
    "#     x = Dense(1000, activation='leaky_relu')(x)\n",
    "#     x = Dense(400, activation='leaky_relu')(x)\n",
    "#     x = Dense(200, activation='leaky_relu')(x)\n",
    "#     x = Dense(actions, activation='leaky_relu')(x)\n",
    "#     outputs = x\n",
    "#     model = Model(inputs=inputs, outputs=outputs)\n",
    "#     return model\n",
    "\n",
    "\n",
    "def build_agent(model, actions):\n",
    "    # policy = MaxBoltzmannQPolicy()\n",
    "    # policy = EpsGreedyQPolicy()\n",
    "    # policy = BoltzmannQPolicy()\n",
    "    policy = LinearAnnealedPolicy(EpsGreedyQPolicy(\n",
    "    ), attr='eps', value_max=1., value_min=.01, value_test=.01, nb_steps=1000000)\n",
    "\n",
    "    # Define the agent\n",
    "    agent = SARSAAgent(model=model, policy=policy,\n",
    "                       nb_actions=actions, nb_steps_warmup=1)\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "run_name = \"sarsa_cnn_9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Main ###\n",
    "\n",
    "\n",
    "# Create the Snake environment\n",
    "env = gym.make('snake-v0', n_foods=1, unit_size=1, unit_gap=0, grid_size=[15, 15], snake_size=3, n_snakes=1)\n",
    "\n",
    "states = (1,) + (15, 15, 3)\n",
    "actions = env.action_space.n\n",
    "\n",
    "# Build the SARSA agent\n",
    "actions = env.action_space.n\n",
    "model = build_model_cnn(states, actions)\n",
    "\n",
    "agent = build_agent(model, actions)\n",
    "agent.compile(Adam(lr=0.0001), metrics=['mae'])\n",
    "\n",
    "\n",
    "# Save the model every n episodes\n",
    "checkpoint_callback = CustomModelCheckpoint(\n",
    "    agent.model, path=run_name + \"_weights_{:d}.h5\", interval=1000)  # saves every 1000 episodes\n",
    "\n",
    "history = agent.fit(env, nb_steps=10000000, visualize=False, verbose=1,\n",
    "                    nb_max_start_steps=1, log_interval=10000, callbacks=[checkpoint_callback])\n",
    "\n",
    "\n",
    "# Save the agent\n",
    "agent.model.save(run_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "print(\"gespeicherte Metriken:\", history.history.keys())\n",
    "\n",
    "plot_history(history.history['episode_reward'], \"episode_reward\", smoothing=True, smoothing_window=100)\n",
    "plot_history(history.history['episode_reward'], \"episode_reward\", smoothing=False)\n",
    "plot_history(history.history['nb_episode_steps'], \"nb_episode_steps\", smoothing=True, smoothing_window=500)\n",
    "plot_history(history.history['nb_steps'], \"nb_steps\", smoothing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "# Test the agent\n",
    "agent.test(env, nb_episodes=3, visualize=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "\n",
    "# loading and testing an existing model\n",
    "\n",
    "states = (1,) + (15, 15, 3)\n",
    "actions = 4\n",
    "\n",
    "model = build_model_cnn(states, actions)\n",
    "agent = build_agent(model, actions)\n",
    "agent.compile(Adam(lr=0.001), metrics=['mae'])\n",
    "\n",
    "# Load the entire model\n",
    "run_name = \"sarsa_cnn_7\"\n",
    "agent.model.load_weights(run_name + '_weights_50000.h5')\n",
    "\n",
    "env = gym.make('snake-v0', n_foods = 1, unit_size=1, unit_gap=0)\n",
    "env.reset() \n",
    "\n",
    "# Build a new agent with the loaded model\n",
    "actions = env.action_space.n\n",
    "new_agent = build_agent(model, actions)\n",
    "new_agent.compile(Adam(lr=0.001), metrics=['mae'])\n",
    "\n",
    "# Run a trial with the new agent\n",
    "new_agent.test(env, nb_episodes=5, visualize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
